üìåüìåüìåüìå1‚É£1Ô∏è‚É£Selenium + playwright

–ª–µ–∫—Ü–∏—è –∏ —Å–µ–º–∏–Ω–∞—Ä

üìÅüìÅüìÅüìÅ
1Ô∏è‚É£ –í–∑—è—Ç—å —Å–∞–π—Ç https://www.wildberries.ru/ –∏ –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –Ω–µ–º—É —á–µ—Ä–µ–∑ Selenium/playwright (—Ä–µ–∫–æ–º–µ–Ω–¥—É—é –≤—Ç–æ—Ä–æ–π)
2Ô∏è‚É£ (3 –±–∞–ª–ª–∞) –£ –≤–∞—Å, —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, —Å—Ä–∞–∑—É –Ω–µ –ø–æ–ª—É—á–∏—Ç—Å—è –∏ –≤–∞–º –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ–µ–π–∫–æ–≤—ã–π –±—Ä–∞—É–∑–µ—Ä (–∫–∞–∫ –ø—Ä–∏–º–µ—Ä, –Ω–∏–∂–µ). –ê –µ—â–µ –ø–æ–±–æ—Ä–æ—Ç—å—Å—è —Å–æ –≤—Å–ø–ª—ã–≤–∞—é—â–∏–º –æ–∫–æ—à–∫–æ–º (—Ç—É—Ç –ø–æ–º–æ–∂–µ—Ç –∑–∞–¥–µ—Ä–∂–∫–∞ –Ω–∞ –ø–∞—Ä—É —Å–µ–∫—É–Ω–¥)
import undetected_chromedriver as uc
from selenium_stealth import stealth

driver = uc.Chrome(version_main=142)
stealth(driver,
    languages=["ru-RU", "ru"],
    vendor="Google Inc.",
    platform="Linux",
    webgl_vendor="Intel Inc.",
    renderer="Intel Iris OpenGL Engine",
    fix_hairline=True,
)
3Ô∏è‚É£ (2 –±–∞–ª–ª–∞) –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ, –Ω–∞–¥–æ –±—É–¥–µ—Ç –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ –≤ –ø–æ–∏—Å–∫–æ–≤—É—é —Å—Ç—Ä–æ–∫—É –≤–±–∏—Ç—å –ï–ª–∫–∞. –°–∫–∞—á–∞—Ç—å –∫–∞—Ä—Ç–æ—á–∫–∏ —Ç–æ–≤–∞—Ä–æ–≤ –µ–ª–∫–∏.
4Ô∏è‚É£ (2 –±–∞–ª–ª–∞) –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ, —Å–æ–±—Ä–∞—Ç—å –≤—Å–µ –µ–ª–∫–∏, –∏—Ö —Ü–µ–Ω—ã, –∏ —Å—Å—ã–ª–∫–∏ –Ω–∞ –∫–∞—Ä—Ç–æ—á–∫–∏ —Å –ø–µ—Ä–≤—ã—Ö –ø—è—Ç–∏ —Å—Ç—Ä–∞–Ω–∏—Ü
5Ô∏è‚É£ (2 –±–∞–ª–ª–∞) –ó–∞–ø–∏—Å–∞—Ç—å –≤ —Ç–∞–±–ª–∏—Ü—É pandas –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ csv.
6Ô∏è‚É£ (1 –±–∞–ª–ª–∞) –ù–∞–π—Ç–∏ —Å–∞–º—É—é –¥–µ—à–µ–≤—É—é –∏ —Å–∞–º—É—é –¥–æ—Ä–æ–≥—É—é –µ–ª–∫—É.

–°–¥–∞–≤–∞—Ç—å ipynb-—Ñ–∞–π–ª. –§–æ—Ä–º–∞ —Å–¥–∞—á–∏

–ò–ò –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å, –∫–∞–∫ –æ–±—ã—á–Ω–æ –æ—Ç—á–µ—Ç –Ω—É–∂–µ–Ω –æ –µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏.

üìÖüìÖüìÖüìÖ 14.12.25 23.59 –º—Å–∫


# Python –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö


–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è `selenium`.

**–ü—Ä–∏–º–µ—Ä.** –ó–∞–π–¥–µ–º –Ω–∞ —Å–∞–π—Ç –∫–Ω–∏–∂–Ω–æ–≥–æ –º–∞–≥–∞–∑–∏–Ω–∞ –∏ –Ω–∞–π–¥–µ–º –≤—Å–µ –∫–Ω–∏–≥–∏ –ø—Ä–æ Python. –ó–∞–≥—Ä—É–∑–∏–º –±–∏–±–ª–∏–æ—Ç–µ–∫—É, –≤–µ–±-–¥—Ä–∞–π–≤–µ—Ä –∏ –æ—Ç–∫—Ä–æ–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –≤ –±—Ä–∞—É–∑–µ—Ä–µ —á–µ—Ä–µ–∑ Python.

!pip install google-colab-selenium

import google_colab_selenium as gs

import requests
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import Select
from time import sleep
import pandas as pd
from selenium.webdriver.chrome.service import Service

driver = gs.Chrome()

!pip install undetected_chromedriver
!pip install selenium_stealth

import undetected_chromedriver as uc
from selenium_stealth import stealth

driver = gs.Chrome()
stealth(driver
    languages=["ru-RU", "ru"],
    vendor="Google Inc.",
    platform="Linux",
    webgl_vendor="Intel Inc.",
    renderer="Intel Iris OpenGL Engine",
    fix_hairline=True,
)
driver.get("https://www.wildberries.ru/")

print(driver.current_url)



driver.get("https://python.org")
print(driver.current_url)

driver.find_element(By.XPATH, "/html/body/div/div[2]/nav/ul/li[3]/a").click()

search_line = driver.find_element(By.NAME, "q")
search_line.clear()
search_line.send_keys("for")
search_line.send_keys(Keys.ENTER)

print(driver.current_url)

print(driver.page_source)

driver.find_element("css selector","#id-search-field")

from selenium.webdriver.common.by import By

driver.find_element(By.XPATH,"/html/body/div/header/div/div[1]/div/form/fieldset/input")

search_line = driver.find_element(By.ID, "id-search-field")

# –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –≤ search_line selenium -- send_keys
search = "selenium"
driver.implicitly_wait(2)
search_line.send_keys(search)
driver.implicitly_wait(2)  # –ø–æ–¥–æ–∂–¥–µ–º –ø–∞—Ä—É —Å–µ–∫—É–Ω–¥

button = driver.find_element(By.XPATH, "/html/body/div/header/div/div[1]/div/form/fieldset/button")

button.text

button.get_attribute("class")

button.click()

driver.current_url



driver.get('http://www.biblio-globus.ru/')
field = driver.find_element("css selector","#SearchBooks")

author = "Python"
driver.implicitly_wait(2)
field.send_keys(author)
driver.implicitly_wait(2)  # –ø–æ–¥–æ–∂–¥–µ–º –ø–∞—Ä—É —Å–µ–∫—É–Ω–¥

submit = driver.find_element("css selector","#SearchButton")
submit.click()

next = driver.find_element(By.XPATH, '/html/body/div[7]/div[1]/div/div/div[2]/div[2]/ul/li[2]/a')
next.click()


page2 = driver.page_source

soup2 = BeautifulSoup(page2, 'html')

books = soup2.find_all('div', class_='col-lg-3 col-md-4 col-sm-6 col-6 wrp_mobile')

books_data = []

for card in books:

    title_tag = card.find('img', class_='card-img')
    title = title_tag.get('alt', '')

    author_tag = card.find('span', class_='card-author')
    author = author_tag.text.strip()

    price_tag = card.find('span', class_='price_item_new')
    price = price_tag.text.strip().replace('\xa0', ' ')

    books_data.append({
            '–ù–∞–∑–≤–∞–Ω–∏–µ': title,
            '–ê–≤—Ç–æ—Ä': author,
            '–¶–µ–Ω–∞': price})

df = pd.DataFrame(books_data)

df.head()



driver.get('http://www.biblio-globus.ru/')
field = driver.find_element("css selector","#SearchBooks")
author = "Python"
driver.implicitly_wait(2)
field.send_keys(author)
driver.implicitly_wait(2)

submit = driver.find_element("css selector","#SearchButton")
submit.click()
page1 = driver.page_source

from bs4 import BeautifulSoup
soup1 = BeautifulSoup(page1, "html")
books = soup1.find_all('div', class_='col-lg-3 col-md-4 col-sm-6 col-6 wrp_mobile')
books_info = []
for b in books:
  title_b = b.find('img',class_= 'card-img')
  title = title_b.get('alt','')
  author_b = b.find('span', class_='card-author')
  author = author_b.text.strip()
  price_b = b.find('span', class_='price_item_new')
  price = price_b.text.strip()
  books_info.append({
    '–ù–∞–∑–≤–∞–Ω–∏–µ':title,
    '–ê–≤—Ç–æ—Ä':author,
    '–¶–µ–Ω–∞':price
})
df = pd.DataFrame(books_info)
df.head()

driver.execute_script("...")

driver.find_elements("css selector","#SearchBooks")

from selenium.webdriver.common.by import By

driver.find_element(By.XPATH,"/html/body/header/div[2]/div[2]/div[2]/div/div/div/div[2]/form/div/div[3]/button")

–ù–∞–π–¥–µ–º —Å –ø–æ–º–æ—â—å—é CSS Selector'–∞ (*SelectorGadget*) –ø–æ–ª–µ –¥–ª—è –≤–≤–æ–¥–∞ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–Ω–∏–≥–∏ –∏–ª–∏ –∞–≤—Ç–æ—Ä–∞.

field = driver.find_element("css selector","#SearchBooks")

field

–°–æ—Ö—Ä–∞–Ω–∏–º –∑–∞–ø—Ä–æ—Å:

author = "Python"  # –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è author - —É—Å–ª–æ–≤–Ω–æ—Å—Ç—å

–í–≤–µ–¥–µ–º –∑–∞–ø—Ä–æ—Å –≤ –ø–æ–ª–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ (`.send_keys`) –∏ –ø–æ–¥–æ–∂–¥–µ–º —á—É—Ç—å-—á—É—Ç—å:

driver.implicitly_wait(2)
field.send_keys(author)
driver.implicitly_wait(2)  # –ø–æ–¥–æ–∂–¥–µ–º –ø–∞—Ä—É —Å–µ–∫—É–Ω–¥

–¢–µ–ø–µ—Ä—å –Ω–∞–π–¥–µ–º –∫–Ω–æ–ø–∫—É –¥–ª—è –ø–æ–∏—Å–∫–∞ (–∑–Ω–∞—á–æ–∫ *–ª—É–ø–∞* —Ä—è–¥–æ–º —Å–æ —Å—Ç—Ä–æ–∫–æ–π –ø–æ–∏—Å–∫–∞) :

#SearchButton

submit = driver.find_element("css selector","#SearchButton")

submit

–ö–ª–∏–∫–Ω–µ–º –Ω–∞ –Ω–µ–µ:

submit.click()

–°–æ—Ö—Ä–∞–Ω–∏–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é `page1`.

page1 = driver.page_source

page1

–¢–µ–ø–µ—Ä—å –æ–±—Ä–∞–±–æ—Ç–∞–µ–º —ç—Ç—É —Å—Ç—Ä–∞–Ω–∏—Ü—É —á–µ—Ä–µ–∑ `BeautifulSoup`:

from bs4 import BeautifulSoup

soup1 = BeautifulSoup(page1, 'html')

soup1

–ù–∞–π–¥–µ–º –≤—Å–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–Ω–∏–≥ –Ω–∞ —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ. –ü–æ –∏—Å—Ö–æ–¥–Ω–æ–º—É –∫–æ–¥—É –º–æ–∂–Ω–æ —É–≤–∏–¥–µ—Ç—å, —á—Ç–æ –æ–Ω–∏ –∏–º–µ—é—Ç —Ç—ç–≥ `a` —Å –∞—Ç—Ä–∏–±—É—Ç–æ–º `class`, —Ä–∞–≤–Ω—ã–º `name`:

print(soup1.prettify())

soup1.find_all('a',{'class':"img-wrapper-index"})

–° –ø–æ–º–æ—â—å—é —Å–ø–∏—Å–∫–æ–≤—ã—Ö –≤–∫–ª—é—á–µ–Ω–∏–π –≤—ã–±–µ—Ä–µ–º –∏–∑ —Å—Å—ã–ª–æ–∫ —Å —Ç—ç–≥–æ–º `<a>` —Ç–µ–∫—Å—Ç (—Ç–∞–∫ –º—ã —É–∂–µ –¥–µ–ª–∞–ª–∏, –∏ –Ω–µ —Ä–∞–∑).

result = soup1.find_all('a',{'class':"img-wrapper-index"})[0]
result

result.find_all('img')



## –ó–∞–¥–∞–Ω–∏–µ

–ü–æ–ª—É—á–∏—Ç—å —Ç–∞–∫–æ–π —Å–ø–∏—Å–æ–∫ –∫–Ω–∏–≥

import pandas as pd

–î–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è —Å–æ–∑–¥–∞–¥–∏–º –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –Ω–µ –∏–∑ —Å–ø–∏—Å–∫–∞ —Å–ø–∏—Å–∫–æ–≤, –∞ –∏–∑ —Å–ª–æ–≤–∞—Ä—è. –ö–ª—é—á–∞–º–∏ —Å–ª–æ–≤–∞—Ä—è –±—É–¥—É—Ç –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤ –≤ —Ç–∞–±–ª–∏—Ü–µ, –∞ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ ‚Äì —Å–ø–∏—Å–∫–∏ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π (–Ω–∞–∑–≤–∞–Ω–∏—è –∫–Ω–∏–≥, —Ü–µ–Ω—ã –∏ –ø—Ä–æ—á.).

df = pd.DataFrame(books_parsed)

df.head()

df.columns = ['–ê–≤—Ç–æ—Ä', '–ù–∞–∑–≤–∞–Ω–∏–µ', '–¶–µ–Ω–∞']

df['–¶–µ–Ω–∞'] = pd.to_numeric(df['–¶–µ–Ω–∞'])

df.info()

–¢–µ–ø–µ—Ä—å –º–æ–∂–µ–º —Ä–∞—Å–ø–æ–ª–æ–∂–∏—Ç—å –∫–Ω–∏–≥–∏ –ø–æ —Ü–µ–Ω–µ –≤ –ø–æ—Ä—è–¥–∫–µ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—è:

df = df.sort_values('–ê–≤—Ç–æ—Ä')

df = df.reset_index(drop=True)

df

–ò —Å–æ—Ö—Ä–∞–Ω–∏–º –≤—Å—é —Ç–∞–±–ª–∏—Ü—É –≤ csv-—Ñ–∞–π–ª:

df.to_csv("books.csv")

## –ó–∞–¥–∞–Ω–∏–µ

–°–æ–±–µ—Ä–∏—Ç–µ —Ç–∞–±–ª–∏—Ü—É —Å –§–ò–û –∞–≤—Ç–æ—Ä–∞, –Ω–∞–∑–≤–∞–Ω–∏–µ–º –∫–Ω–∏–≥–∏ –∏ –µ–µ —Å—Ç–æ–∏–º–æ—Å—Ç—å—é —Å–æ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü –ø–æ –∑–∞–ø—Ä–æ—Å—É "Python".

l = []
try:
    while True:
        next_page_btn = driver.find_element("css selector",".active + .page-item")
        sleep(2)
        soup1 = BeautifulSoup(page1, 'html')
        l.extend(soup1.find_all('a',{'class':"img-wrapper-index"}))
        sleep(2)
        next_page_btn.click()
except:
    print('Finished!')

l

!pip install playwright
!playwright install

!playwright install chromium
!playwright install firefox
!playwright install webkit

!apt-get update
!apt-get install -y libatk1.0-0 libatk-bridge2.0-0 libatspi2.0-0 libxcomposite1 libxdamage1 \
    libxfixes3 libxrandr2 libgbm1 libxkbcommon0 libpango-1.0-0 libcairo2 \
    libasound2 libpangocairo-1.0-0 libnss3 libxshmfence1 fonts-liberation \
    libwayland-client0 libwayland-server0 libappindicator3-1 libdbusmenu-glib4 \
    libdbusmenu-gtk3-4 libxtst6 libxss1 libx11-xcb1


!pip install playwright nest_asyncio
!playwright install chromium


import asyncio
import nest_asyncio
from playwright.async_api import async_playwright

nest_asyncio.apply()

async def run():
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()

        await page.goto("https://example.com")
        print(await page.title())

        await browser.close()

await run()

import asyncio
import nest_asyncio
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup
import pandas as pd

nest_asyncio.apply()
async def run():
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        await page.goto("http://www.biblio-globus.ru/")
        # print(await page.title())
        search = page.locator('input[placeholder="–ü–æ–∏—Å–∫..."]').first
        await search.fill("Python")
        await search.press("Enter")
        await page.wait_for_load_state("networkidle")

        html = await page.content()
        soup = BeautifulSoup(html, "html.parser")
        books = soup.find_all("div", class_="col-lg-3 col-md-4 col-sm-6 col-6 wrp_mobile")

        books_info = []
        for b in books:
            img = b.find("img", class_="card-img")
            title = img.get("alt", "")
            author_b = b.find('span', class_='card-author')
            author = author_b.text.strip()
            price_b = b.find('span', class_='price_item_new')
            price = price_b.text.strip()
            books_info.append({
              '–ù–∞–∑–≤–∞–Ω–∏–µ':title,
              '–ê–≤—Ç–æ—Ä':author,
              '–¶–µ–Ω–∞':price
            })
        df = pd.DataFrame(books_info)
        print(df.head())
        await browser.close()
await run()

!pip install fake_useragent

from fake_useragent import UserAgent

ua = UserAgent()

import asyncio
import nest_asyncio
from playwright.async_api import async_playwright


async def run():
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        # browser = await p.chromium.launch(headless=True)
        # context = browser.new_context(
        #     user_agent=ua.random,
        #     viewport={'width': 1920, 'height': 1080}
        # )
        # page = context.new_page()

        await page.goto("https://www.biblio-globus.ru/")
        await page.screenshot(path="page.png")
        print(await page.title())
        search = page.locator('input[placeholder="–ü–æ–∏—Å–∫..."]').first
        await search.fill('Python')
        await search.press("Enter")
        await page.wait_for_load_state("networkidle")
        html = await page.content()
        print(html)
        soup = BeautifulSoup(html, "html.parser")
        books = soup.find_all("div", class_="col-lg-3 col-md-4 col-sm-6 col-6 wrp_mobile")

        books_info = []
        for b in books:
            img = b.find("img", class_="card-img")
            title = img.get("alt", "")
            author_b = b.find('span', class_='card-author')
            author = author_b.text.strip()
            price_b = b.find('span', class_='price_item_new')
            price = price_b.text.strip()
            books_info.append({
              '–ù–∞–∑–≤–∞–Ω–∏–µ':title,
              '–ê–≤—Ç–æ—Ä':author,
              '–¶–µ–Ω–∞':price
            })
        df = pd.DataFrame(books_info)
        print(df.head())
        await browser.close()

await run()

# fill(), press(), click(), type(), check(), select_option()

